<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script type=text/javascript src=//pl16811434.highcpmrevenuenetwork.com/a9/3a/ae/a93aae05ef8189322f739e43754a240d.js></script><title>Just How Good Are The New Wave Of Ai Image Generation Tools | gamestrex</title><meta name=keywords content><meta name=description content="However, as with any groundbreaking technology, there&rsquo;s plenty of controversy too: what role does the artist play if machine learning can generate high quality imagery so quickly and so easily? And what of the data used to train these AIs - is there an argument that machine learning-generated images are created by effectively passing off the work of human artists? There are major ethical questions to grapple with once these technologies reach a certain degree of effectiveness - and based on the rapid pace of improvement I&rsquo;ve seen, the questions may need to be addressed sooner rather than later."><meta name=author content="Rosemary Soltis"><link rel=canonical href=https://gamestrex.github.io/posts/just-how-good-are-the-new-wave-of-ai-image-generation-tools-/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://gamestrex.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://gamestrex.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://gamestrex.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://gamestrex.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://gamestrex.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Just How Good Are The New Wave Of Ai Image Generation Tools "><meta property="og:description" content="However, as with any groundbreaking technology, there&rsquo;s plenty of controversy too: what role does the artist play if machine learning can generate high quality imagery so quickly and so easily? And what of the data used to train these AIs - is there an argument that machine learning-generated images are created by effectively passing off the work of human artists? There are major ethical questions to grapple with once these technologies reach a certain degree of effectiveness - and based on the rapid pace of improvement I&rsquo;ve seen, the questions may need to be addressed sooner rather than later."><meta property="og:type" content="article"><meta property="og:url" content="https://gamestrex.github.io/posts/just-how-good-are-the-new-wave-of-ai-image-generation-tools-/"><meta property="og:image" content="https://gamestrex.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-01T00:00:00+00:00"><meta property="article:modified_time" content="2023-01-01T00:00:00+00:00"><meta property="og:site_name" content="gamestrex"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gamestrex.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Just How Good Are The New Wave Of Ai Image Generation Tools "><meta name=twitter:description content="However, as with any groundbreaking technology, there&rsquo;s plenty of controversy too: what role does the artist play if machine learning can generate high quality imagery so quickly and so easily? And what of the data used to train these AIs - is there an argument that machine learning-generated images are created by effectively passing off the work of human artists? There are major ethical questions to grapple with once these technologies reach a certain degree of effectiveness - and based on the rapid pace of improvement I&rsquo;ve seen, the questions may need to be addressed sooner rather than later."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://gamestrex.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Just How Good Are The New Wave Of Ai Image Generation Tools ","item":"https://gamestrex.github.io/posts/just-how-good-are-the-new-wave-of-ai-image-generation-tools-/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Just How Good Are The New Wave Of Ai Image Generation Tools ","name":"Just How Good Are The New Wave Of Ai Image Generation Tools ","description":"However, as with any groundbreaking technology, there\u0026rsquo;s plenty of controversy too: what role does the artist play if machine learning can generate high quality imagery so quickly and so easily? And what of the data used to train these AIs - is there an argument that machine learning-generated images are created by effectively passing off the work of human artists? There are major ethical questions to grapple with once these technologies reach a certain degree of effectiveness - and based on the rapid pace of improvement I\u0026rsquo;ve seen, the questions may need to be addressed sooner rather than later.","keywords":[],"articleBody":" However, as with any groundbreaking technology, there’s plenty of controversy too: what role does the artist play if machine learning can generate high quality imagery so quickly and so easily? And what of the data used to train these AIs - is there an argument that machine learning-generated images are created by effectively passing off the work of human artists? There are major ethical questions to grapple with once these technologies reach a certain degree of effectiveness - and based on the rapid pace of improvement I’ve seen, the questions may need to be addressed sooner rather than later.\rIn the meantime, the focus of this piece is to see just how effective these technologies are right now. I tried three of the leading AI generators: DALL-E 2, Stable Diffusion, and Midjourney. You can see the results of these technologies in the embedded video below (and indeed in the collage at the top of this page) but to be clear, I generated all of them, either by using their web portals or else running them directly on local hardware. At the moment, the default way of using AI image generators is through something called ‘prompting’. Essentially, you simply write what you’d like the AI to generate and it does its best to create it for you. Using DALL-E 2, for example, the best way to prompt it seems to be to use a combination of a simple description, plus some sort of stylisation, or indication of how you’d like the image to look. Attaching a lot of descriptors at the end of a prompt often helps the AI deliver a high quality result. There’s another form of prompting that involves giving the software a base image to work with, along with a verbal prompt that essentially guides the software to create a new image. Right now this is only available in Stable Diffusion. Like many other AI techniques, AI image generation works by sampling a large variety of inputs - in this case, databases of images - and coming up with parameters based on that work. In broad strokes, it’s similar to the way that DLSS or XeSS work, or other machine learning applications like the text generator GPT-3. On some level, the AI is ’learning’ how to create art with superhuman versatility and speed. Conceptually at least, AI art generation should be limited by its dataset - the collection of billions of images and keywords that it was trained on. In practice, there are so many inputs that these tools have been trained on that they end up being very flexible. At their best, they demonstrate human-like creativity when subjected to complex or abstract prompts, as the AI has, in a sense, ’learned’ how we generally understand and categorise visual information. Plus, image generators produce outputs based on random seeds - meaning that the same set of keywords can produce different interesting new results each time you run it. The positive implications for the video game industry are numerous. For example, remasters are becoming ever-more common. However, older titles come saddled with technical baggage. Some problems are easy to overcome, but updating the source artwork - in particular, the textures - used for those games often takes an enormous amount of effort and time. That being the case, it was no surprise that when AI upscaling techniques became popular starting around 2020, they immediately saw use across a wide variety of remastering efforts. Games like Chrono Cross: The Radical Dreamers Edition, Mass Effect Legendary Edition, and the Definitive Edition Grand Theft Auto titles all used AI upscaling to mixed effect. AI upscaling works very well when working with relatively high-quality source artwork with simpler kinds of detail but current AI upscaling models really struggle with lower resolution art, producing artifact-ridden results. But what if we generated all-new assets instead of merely trying to add detail? That’s where AI image generation comes in. Take the Chrono Cross remaster, for example. The original game’s artwork is pretty low resolution and the AI upscaling work does a reasonable job but ends up looking a bit messy. However, if we feed the source imagery into Stable Diffusion and add appropriate prompt material, we can generate all-new high quality artwork that maintains similar visual compositions. We can redraw this cave area with the same fungal shapes and rocks, just at a much higher level of fidelity. By modifying some parameters, we can generate something very close to the original, or pieces that rework the scene by reinterpreting certain areas, like the pathway near the centre. There are other examples in the video above.\rTraditional textures in 3D games are a good target as well. Resident Evil 4 runs on most modern platforms nowadays but its sixth-gen era texture work looks quite messy. Modern games try to depict more complex details in texture work, so simply upscaling or upsampling the original textures doesn’t work very well. Again, by using original texture assets as an input we can generate high-quality artwork with much more natural looking detail. The software reinterprets the original work with our verbal prompt as a guide, producing high fidelity results in seconds. You could, of course, apply the same techniques to creating original assets for games. Provide a source image, like a photograph or an illustration, and generate a new texture asset or piece of artwork for your game. Alternatively, you could just provide a prompt and allow the AI system to generate brand new art without an image to directly guide it. The possibilities here seem virtually endless. Asset creation in the game industry is a huge constraint on development resources, and these sorts of tools have the potential to massively speed up workflows. Potentially, Stable Diffusion seems quite powerful for these sorts of applications, as you can easily queue up hundreds of images at once on your computer for free and cherry-pick the best results. DALL-E 2 and Midjourney also don’t currently allow you to work from a specific source image, so trying to match a piece of existing art is much more challenging. Stable Diffusion also has an option to generate tileable images, which should help with creating textures. I can see these tools being used earlier in the production process as well. During development, studios need countless pieces of concept art. This artwork tends to guide the look of the game and provides reference for the game’s models and textures. At the moment, this is done by hand using digital tools, like graphics tablets, and is very labour-intensive - but AI art tools are capable of generating artwork extremely quickly. Plug in a few parameters and you can easily generate hundreds of examples to work from. Characters, environments, surfaces - it’s all trivial to generate with some decent prompting and a few moments of processing time. Key concept art techniques translate to these AI workflows too. A lot of concept art is made by looking at a 3D model or rough sketch and doing a ‘paintover’, which is when an artist draws detail on a simplified representation of a scene. By feeding the AI a base image to guide composition, we can do the exact same thing. We can provide it with a basic sketch, a 3D model, or even the simplest of compositional drawings, and it will work from that to create a high-quality piece of concept art. Just block out the most basic visual shape, combine it with a verbal prompt and you can get a great result that matches what you need from the composition. Impressive results are achievable but it is important to stress that current AI models are hardly infallible. Actually working out a coherent aesthetic across multiple pieces of artwork can be tricky, as even an identical set of descriptive keywords produce quite different results depending on what you ask it to depict. Different subject areas in commercial artwork tend to use different techniques and this gets reflected in the AI outputs. To generate consistent looking imagery, you need to carefully engineer your prompts. And even still, getting something like what you’re looking for requires some cherry-picking. AI art does seem like a very useful tool, but it does have its limits at the moment. In the past, I have worked on digital art, as well as motion graphics that made heavy use of my own illustrations and graphic art. AI image generation tools seem uniquely well-suited to this sort of work, as they require high volumes of art. You could also imagine a future AI that was capable of generating these results for the entire picture in real time. Right now these techniques take seconds of processing, even on fast GPUs, but perhaps a combination of new hardware and optimisation could produce results good enough for use at runtime.\rIt’s also very easy of course to simply take the generated images and plug them into conventional image editing programs to correct any mistakes, or to add or remove elements. A few minor touch-ups can eliminate any distracting AI artifacts or errors. Keep in mind as well that future AI image generation software is likely to be even more impressive than this - while these aren’t first-generation projects exactly, research and product development in this field has been somewhat limited until recently. I’d expect a potential ‘DALL-E 3’ or ‘Stabler Diffusion’ to deliver more compelling and consistent results. Clearly these products work well right now though, so which is the best option? In terms of quality, DALL-E 2 is very capable of interpreting abstract inputs and generating creative results. If you want to be specific, you can, but the AI often works perfectly well when given a vague prompt and left to its own devices. It’s very creative - DALL-E is able to associate and pull concepts together sensibly based on loose ideas and themes. It’s also generally very good at creating coherent images, for instance consistently generating humans that have the correct number of limbs and in the correct proportions. Stable Diffusion tends to require much more hand-holding. At the moment, it struggles to understand more general concepts, but if you feed it plenty of keywords, it can deliver very good results as well. The big advantage of Stable Diffusion is its image prompting mode, which is very powerful. And if you turn up the settings, you can get some extremely high-quality results - probably the best of the current AI generators. Midjourney is quite good at stylisation - taking an existing concept and rendering it like a certain type of painting or illustration, for instance. It also works very well with simple prompts and can deliver very high-quality results - but it’s perhaps a bit less ‘creative’. Midjourney also tends to exhibit more AI artifacts than the other two generators and often has issues maintaining correct proportions. In my opinion, it’s the worst of the three. DALL-E 2 and Midjourney are both commercial and web-based, but have relatively slick web interfaces that are easy to use. DALL-E 2 unfortunately has been invite-only since its launch in April, though you can apply to a waitlist if you like. Stable Diffusion on the other hand is totally free and open-source. The real upside is that Stable Diffusion can run on local hardware and can be integrated into existing workflows very easily. This wouldn’t be Digital Foundry without some performance analysis. DALL-E 2 is quite a bit faster than Midjourney, though as both run through web portals your personal hardware doesn’t matter. DALL-E 2 usually takes about 10 seconds for a basic image generation at the moment, while Midjourney takes a minute or so. Running Stable Diffusion locally produces variable results, depending on your hardware and the quality level of the output. At 512x512 resolution with a low detail step count, it takes only three or four seconds to create an image on my laptop with a mobile RTX 3080. However, ramp up the level of detail, and increase the resolution, and each image takes 30 or 40 seconds to resolve. Using more advanced samplers can also drive up the generation time. There are many other implementations of Stable Diffusion available for download, some of which may differ significantly from the simple GUI version I was running, though I expect performance characteristics should be similar. To run Stable Diffusion properly, you’ll need a 10-series or later Nvidia GPU with as much VRAM as possible. With 8GB on my mobile 3080 I can generate images up to a maximum of just 640x640, though of course you can AI upscale those images afterwards for a cleaner result. There are other ways to get Stable Diffusion up and running, including workarounds to get it running on AMD GPUs as well as on Apple Silicon-based Mac computers but using a fast Nvidia GPU is the most straightforward option at the moment. Based on my experiences, AI image generation is a stunning, disruptive technology. Type some words in, and get a picture out. It’s the stuff of science fiction but it’s here today and it works remarkably well - and remember, this is just the beginning. Use-cases for this tech are already abundant but I do feel like we are just seeing the tip of the iceberg. High quality AI image generation has only been widely available for a short time, and new and interesting integrations are popping up every day. Gaming in particular seems like an area with a lot of potential, especially as the technology becomes more broadly understood. The most significant barrier at this point is pricing. DALL-E 2 is fairly costly to use and Stable Diffusion essentially demands a reasonably fast Nvidia GPU if you want to run it locally. Getting a high-quality image often requires discarding large numbers of bad ones, so AI tools can be expensive - either in money or in time. Exactly how far will these tools go? For the last half-decade or so, AI art was nothing more than an amusing novelty, producing crude and vague imagery with no commercial purpose. However, in the last year - specifically, the last four or so months - we’ve seen the release of several seriously high-quality AI solutions. It remains to be seen whether AI inference for art will continue to progress at a rapid pace or whether there may be unforeseen limits ahead. Ultimately though, a powerful new tool for asset creation is emerging - and I’ll be intrigued to see just how prevalent its use becomes in the games we play.\n","wordCount":"2421","inLanguage":"en","datePublished":"2023-01-01T00:00:00Z","dateModified":"2023-01-01T00:00:00Z","author":{"@type":"Person","name":"Rosemary Soltis"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://gamestrex.github.io/posts/just-how-good-are-the-new-wave-of-ai-image-generation-tools-/"},"publisher":{"@type":"Organization","name":"gamestrex","logo":{"@type":"ImageObject","url":"https://gamestrex.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://gamestrex.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://gamestrex.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://gamestrex.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://gamestrex.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://gamestrex.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://gamestrex.github.io/posts/>Posts</a></div><h1 class=post-title>Just How Good Are The New Wave Of Ai Image Generation Tools</h1><div class=post-meta><span title='2023-01-01 00:00:00 +0000 UTC'>January 1, 2023</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;2421 words&nbsp;·&nbsp;Rosemary Soltis</div></header><div class=post-content><hr><p>However, as with any groundbreaking technology, there&rsquo;s plenty of controversy too: what role does the artist play if machine learning can generate high quality imagery so quickly and so easily? And what of the data used to train these AIs - is there an argument that machine learning-generated images are created by effectively passing off the work of human artists? There are major ethical questions to grapple with once these technologies reach a certain degree of effectiveness - and based on the rapid pace of improvement I&rsquo;ve seen, the questions may need to be addressed sooner rather than later.
In the meantime, the focus of this piece is to see just how effective these technologies are right now. I tried three of the leading AI generators: DALL-E 2, Stable Diffusion, and Midjourney. You can see the results of these technologies in the embedded video below (and indeed in the collage at the top of this page) but to be clear, I generated all of them, either by using their web portals or else running them directly on local hardware.
At the moment, the default way of using AI image generators is through something called &lsquo;prompting&rsquo;. Essentially, you simply write what you&rsquo;d like the AI to generate and it does its best to create it for you. Using DALL-E 2, for example, the best way to prompt it seems to be to use a combination of a simple description, plus some sort of stylisation, or indication of how you&rsquo;d like the image to look. Attaching a lot of descriptors at the end of a prompt often helps the AI deliver a high quality result.
There&rsquo;s another form of prompting that involves giving the software a base image to work with, along with a verbal prompt that essentially guides the software to create a new image. Right now this is only available in Stable Diffusion. Like many other AI techniques, AI image generation works by sampling a large variety of inputs - in this case, databases of images - and coming up with parameters based on that work. In broad strokes, it&rsquo;s similar to the way that DLSS or XeSS work, or other machine learning applications like the text generator GPT-3. On some level, the AI is &rsquo;learning&rsquo; how to create art with superhuman versatility and speed.
Conceptually at least, AI art generation should be limited by its dataset - the collection of billions of images and keywords that it was trained on. In practice, there are so many inputs that these tools have been trained on that they end up being very flexible. At their best, they demonstrate human-like creativity when subjected to complex or abstract prompts, as the AI has, in a sense, &rsquo;learned&rsquo; how we generally understand and categorise visual information. Plus, image generators produce outputs based on random seeds - meaning that the same set of keywords can produce different interesting new results each time you run it.
The positive implications for the video game industry are numerous. For example, remasters are becoming ever-more common. However, older titles come saddled with technical baggage. Some problems are easy to overcome, but updating the source artwork - in particular, the textures - used for those games often takes an enormous amount of effort and time. That being the case, it was no surprise that when AI upscaling techniques became popular starting around 2020, they immediately saw use across a wide variety of remastering efforts. Games like Chrono Cross: The Radical Dreamers Edition, Mass Effect Legendary Edition, and the Definitive Edition Grand Theft Auto titles all used AI upscaling to mixed effect. AI upscaling works very well when working with relatively high-quality source artwork with simpler kinds of detail but current AI upscaling models really struggle with lower resolution art, producing artifact-ridden results.
But what if we generated all-new assets instead of merely trying to add detail? That&rsquo;s where AI image generation comes in. Take the Chrono Cross remaster, for example. The original game&rsquo;s artwork is pretty low resolution and the AI upscaling work does a reasonable job but ends up looking a bit messy. However, if we feed the source imagery into Stable Diffusion and add appropriate prompt material, we can generate all-new high quality artwork that maintains similar visual compositions. We can redraw this cave area with the same fungal shapes and rocks, just at a much higher level of fidelity. By modifying some parameters, we can generate something very close to the original, or pieces that rework the scene by reinterpreting certain areas, like the pathway near the centre. There are other examples in the video above.
Traditional textures in 3D games are a good target as well. Resident Evil 4 runs on most modern platforms nowadays but its sixth-gen era texture work looks quite messy. Modern games try to depict more complex details in texture work, so simply upscaling or upsampling the original textures doesn&rsquo;t work very well. Again, by using original texture assets as an input we can generate high-quality artwork with much more natural looking detail. The software reinterprets the original work with our verbal prompt as a guide, producing high fidelity results in seconds.
You could, of course, apply the same techniques to creating original assets for games. Provide a source image, like a photograph or an illustration, and generate a new texture asset or piece of artwork for your game. Alternatively, you could just provide a prompt and allow the AI system to generate brand new art without an image to directly guide it. The possibilities here seem virtually endless. Asset creation in the game industry is a huge constraint on development resources, and these sorts of tools have the potential to massively speed up workflows.
Potentially, Stable Diffusion seems quite powerful for these sorts of applications, as you can easily queue up hundreds of images at once on your computer for free and cherry-pick the best results. DALL-E 2 and Midjourney also don&rsquo;t currently allow you to work from a specific source image, so trying to match a piece of existing art is much more challenging. Stable Diffusion also has an option to generate tileable images, which should help with creating textures.
I can see these tools being used earlier in the production process as well. During development, studios need countless pieces of concept art. This artwork tends to guide the look of the game and provides reference for the game&rsquo;s models and textures. At the moment, this is done by hand using digital tools, like graphics tablets, and is very labour-intensive - but AI art tools are capable of generating artwork extremely quickly. Plug in a few parameters and you can easily generate hundreds of examples to work from. Characters, environments, surfaces - it&rsquo;s all trivial to generate with some decent prompting and a few moments of processing time.
Key concept art techniques translate to these AI workflows too. A lot of concept art is made by looking at a 3D model or rough sketch and doing a &lsquo;paintover&rsquo;, which is when an artist draws detail on a simplified representation of a scene. By feeding the AI a base image to guide composition, we can do the exact same thing. We can provide it with a basic sketch, a 3D model, or even the simplest of compositional drawings, and it will work from that to create a high-quality piece of concept art. Just block out the most basic visual shape, combine it with a verbal prompt and you can get a great result that matches what you need from the composition.
Impressive results are achievable but it is important to stress that current AI models are hardly infallible. Actually working out a coherent aesthetic across multiple pieces of artwork can be tricky, as even an identical set of descriptive keywords produce quite different results depending on what you ask it to depict. Different subject areas in commercial artwork tend to use different techniques and this gets reflected in the AI outputs. To generate consistent looking imagery, you need to carefully engineer your prompts. And even still, getting something like what you&rsquo;re looking for requires some cherry-picking. AI art does seem like a very useful tool, but it does have its limits at the moment.
In the past, I have worked on digital art, as well as motion graphics that made heavy use of my own illustrations and graphic art. AI image generation tools seem uniquely well-suited to this sort of work, as they require high volumes of art. You could also imagine a future AI that was capable of generating these results for the entire picture in real time. Right now these techniques take seconds of processing, even on fast GPUs, but perhaps a combination of new hardware and optimisation could produce results good enough for use at runtime.
It&rsquo;s also very easy of course to simply take the generated images and plug them into conventional image editing programs to correct any mistakes, or to add or remove elements. A few minor touch-ups can eliminate any distracting AI artifacts or errors. Keep in mind as well that future AI image generation software is likely to be even more impressive than this - while these aren&rsquo;t first-generation projects exactly, research and product development in this field has been somewhat limited until recently. I&rsquo;d expect a potential &lsquo;DALL-E 3&rsquo; or &lsquo;Stabler Diffusion&rsquo; to deliver more compelling and consistent results.
Clearly these products work well right now though, so which is the best option? In terms of quality, DALL-E 2 is very capable of interpreting abstract inputs and generating creative results. If you want to be specific, you can, but the AI often works perfectly well when given a vague prompt and left to its own devices. It&rsquo;s very creative - DALL-E is able to associate and pull concepts together sensibly based on loose ideas and themes. It&rsquo;s also generally very good at creating coherent images, for instance consistently generating humans that have the correct number of limbs and in the correct proportions.
Stable Diffusion tends to require much more hand-holding. At the moment, it struggles to understand more general concepts, but if you feed it plenty of keywords, it can deliver very good results as well. The big advantage of Stable Diffusion is its image prompting mode, which is very powerful. And if you turn up the settings, you can get some extremely high-quality results - probably the best of the current AI generators.
Midjourney is quite good at stylisation - taking an existing concept and rendering it like a certain type of painting or illustration, for instance. It also works very well with simple prompts and can deliver very high-quality results - but it&rsquo;s perhaps a bit less &lsquo;creative&rsquo;. Midjourney also tends to exhibit more AI artifacts than the other two generators and often has issues maintaining correct proportions. In my opinion, it&rsquo;s the worst of the three.
DALL-E 2 and Midjourney are both commercial and web-based, but have relatively slick web interfaces that are easy to use. DALL-E 2 unfortunately has been invite-only since its launch in April, though you can apply to a waitlist if you like. Stable Diffusion on the other hand is totally free and open-source. The real upside is that Stable Diffusion can run on local hardware and can be integrated into existing workflows very easily.
This wouldn&rsquo;t be Digital Foundry without some performance analysis. DALL-E 2 is quite a bit faster than Midjourney, though as both run through web portals your personal hardware doesn&rsquo;t matter. DALL-E 2 usually takes about 10 seconds for a basic image generation at the moment, while Midjourney takes a minute or so. Running Stable Diffusion locally produces variable results, depending on your hardware and the quality level of the output.
At 512x512 resolution with a low detail step count, it takes only three or four seconds to create an image on my laptop with a mobile RTX 3080. However, ramp up the level of detail, and increase the resolution, and each image takes 30 or 40 seconds to resolve. Using more advanced samplers can also drive up the generation time. There are many other implementations of Stable Diffusion available for download, some of which may differ significantly from the simple GUI version I was running, though I expect performance characteristics should be similar.
To run Stable Diffusion properly, you&rsquo;ll need a 10-series or later Nvidia GPU with as much VRAM as possible. With 8GB on my mobile 3080 I can generate images up to a maximum of just 640x640, though of course you can AI upscale those images afterwards for a cleaner result. There are other ways to get Stable Diffusion up and running, including workarounds to get it running on AMD GPUs as well as on Apple Silicon-based Mac computers but using a fast Nvidia GPU is the most straightforward option at the moment.
Based on my experiences, AI image generation is a stunning, disruptive technology. Type some words in, and get a picture out. It&rsquo;s the stuff of science fiction but it&rsquo;s here today and it works remarkably well - and remember, this is just the beginning. Use-cases for this tech are already abundant but I do feel like we are just seeing the tip of the iceberg. High quality AI image generation has only been widely available for a short time, and new and interesting integrations are popping up every day. Gaming in particular seems like an area with a lot of potential, especially as the technology becomes more broadly understood.
The most significant barrier at this point is pricing. DALL-E 2 is fairly costly to use and Stable Diffusion essentially demands a reasonably fast Nvidia GPU if you want to run it locally. Getting a high-quality image often requires discarding large numbers of bad ones, so AI tools can be expensive - either in money or in time. Exactly how far will these tools go? For the last half-decade or so, AI art was nothing more than an amusing novelty, producing crude and vague imagery with no commercial purpose. However, in the last year - specifically, the last four or so months - we&rsquo;ve seen the release of several seriously high-quality AI solutions. It remains to be seen whether AI inference for art will continue to progress at a rapid pace or whether there may be unforeseen limits ahead. Ultimately though, a powerful new tool for asset creation is emerging - and I&rsquo;ll be intrigued to see just how prevalent its use becomes in the games we play.</p><p><img loading=lazy src=https://assets.reedpopcdn.com/Chrono_LrVQsTm.jpg/BROK/resize/690%3E/format/jpg/quality/75/Chrono_LrVQsTm.jpg onerror='this.onerror=null,this.src="https://blogger.googleusercontent.com/img/a/AVvXsEhe7F7TRXHtjiKvHb5vS7DmnxvpHiDyoYyYvm1nHB3Qp2_w3BnM6A2eq4v7FYxCC9bfZt3a9vIMtAYEKUiaDQbHMg-ViyGmRIj39MLp0bGFfgfYw1Dc9q_H-T0wiTm3l0Uq42dETrN9eC8aGJ9_IORZsxST1AcLR7np1koOfcc7tnHa4S8Mwz_xD9d0=s16000"' alt="Just how good are the new wave of AI image generation tools  - 10"><img loading=lazy src=https://assets.reedpopcdn.com/CC-1.jpg/BROK/resize/690%3E/format/jpg/quality/75/CC-1.jpg onerror='this.onerror=null,this.src="https://blogger.googleusercontent.com/img/a/AVvXsEhe7F7TRXHtjiKvHb5vS7DmnxvpHiDyoYyYvm1nHB3Qp2_w3BnM6A2eq4v7FYxCC9bfZt3a9vIMtAYEKUiaDQbHMg-ViyGmRIj39MLp0bGFfgfYw1Dc9q_H-T0wiTm3l0Uq42dETrN9eC8aGJ9_IORZsxST1AcLR7np1koOfcc7tnHa4S8Mwz_xD9d0=s16000"' alt="Just how good are the new wave of AI image generation tools  - 23"><img loading=lazy src=https://assets.reedpopcdn.com/CC-2.jpg/BROK/resize/690%3E/format/jpg/quality/75/CC-2.jpg onerror='this.onerror=null,this.src="https://blogger.googleusercontent.com/img/a/AVvXsEhe7F7TRXHtjiKvHb5vS7DmnxvpHiDyoYyYvm1nHB3Qp2_w3BnM6A2eq4v7FYxCC9bfZt3a9vIMtAYEKUiaDQbHMg-ViyGmRIj39MLp0bGFfgfYw1Dc9q_H-T0wiTm3l0Uq42dETrN9eC8aGJ9_IORZsxST1AcLR7np1koOfcc7tnHa4S8Mwz_xD9d0=s16000"' alt="Just how good are the new wave of AI image generation tools  - 70"><img loading=lazy src=https://assets.reedpopcdn.com/CC-3.jpg/BROK/resize/690%3E/format/jpg/quality/75/CC-3.jpg onerror='this.onerror=null,this.src="https://blogger.googleusercontent.com/img/a/AVvXsEhe7F7TRXHtjiKvHb5vS7DmnxvpHiDyoYyYvm1nHB3Qp2_w3BnM6A2eq4v7FYxCC9bfZt3a9vIMtAYEKUiaDQbHMg-ViyGmRIj39MLp0bGFfgfYw1Dc9q_H-T0wiTm3l0Uq42dETrN9eC8aGJ9_IORZsxST1AcLR7np1koOfcc7tnHa4S8Mwz_xD9d0=s16000"' alt="Just how good are the new wave of AI image generation tools  - 80"><img loading=lazy src=https://assets.reedpopcdn.com/CC-4.jpg/BROK/resize/690%3E/format/jpg/quality/75/CC-4.jpg onerror='this.onerror=null,this.src="https://blogger.googleusercontent.com/img/a/AVvXsEhe7F7TRXHtjiKvHb5vS7DmnxvpHiDyoYyYvm1nHB3Qp2_w3BnM6A2eq4v7FYxCC9bfZt3a9vIMtAYEKUiaDQbHMg-ViyGmRIj39MLp0bGFfgfYw1Dc9q_H-T0wiTm3l0Uq42dETrN9eC8aGJ9_IORZsxST1AcLR7np1koOfcc7tnHa4S8Mwz_xD9d0=s16000"' alt="Just how good are the new wave of AI image generation tools  - 70"><img loading=lazy src=https://assets.reedpopcdn.com/concept.jpg/BROK/resize/690%3E/format/jpg/quality/75/concept.jpg onerror='this.onerror=null,this.src="https://blogger.googleusercontent.com/img/a/AVvXsEhe7F7TRXHtjiKvHb5vS7DmnxvpHiDyoYyYvm1nHB3Qp2_w3BnM6A2eq4v7FYxCC9bfZt3a9vIMtAYEKUiaDQbHMg-ViyGmRIj39MLp0bGFfgfYw1Dc9q_H-T0wiTm3l0Uq42dETrN9eC8aGJ9_IORZsxST1AcLR7np1koOfcc7tnHa4S8Mwz_xD9d0=s16000"' alt="Just how good are the new wave of AI image generation tools  - 66"><img loading=lazy src=https://assets.reedpopcdn.com/AI-From-Nothing.jpg/BROK/resize/690%3E/format/jpg/quality/75/AI-From-Nothing.jpg onerror='this.onerror=null,this.src="https://blogger.googleusercontent.com/img/a/AVvXsEhe7F7TRXHtjiKvHb5vS7DmnxvpHiDyoYyYvm1nHB3Qp2_w3BnM6A2eq4v7FYxCC9bfZt3a9vIMtAYEKUiaDQbHMg-ViyGmRIj39MLp0bGFfgfYw1Dc9q_H-T0wiTm3l0Uq42dETrN9eC8aGJ9_IORZsxST1AcLR7np1koOfcc7tnHa4S8Mwz_xD9d0=s16000"' alt="Just how good are the new wave of AI image generation tools  - 39"><img loading=lazy src=https://assets.reedpopcdn.com/DF_1.jpg/BROK/resize/690%3E/format/jpg/quality/75/DF_1.jpg onerror='this.onerror=null,this.src="https://blogger.googleusercontent.com/img/a/AVvXsEhe7F7TRXHtjiKvHb5vS7DmnxvpHiDyoYyYvm1nHB3Qp2_w3BnM6A2eq4v7FYxCC9bfZt3a9vIMtAYEKUiaDQbHMg-ViyGmRIj39MLp0bGFfgfYw1Dc9q_H-T0wiTm3l0Uq42dETrN9eC8aGJ9_IORZsxST1AcLR7np1koOfcc7tnHa4S8Mwz_xD9d0=s16000"' alt="Just how good are the new wave of AI image generation tools  - 96"></p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://gamestrex.github.io/posts/just-cause-4-gold-edition-download-game-ps3-ps4-ps2-rpcs3-pc-free/><span class=title>« Prev</span><br><span>Just Cause 4 Gold Edition Download Game Ps3 Ps4 Ps2 Rpcs3 Pc Free</span></a>
<a class=next href=https://gamestrex.github.io/posts/just-one-line-free-pc-download/><span class=title>Next »</span><br><span>Just One Line Free Pc Download</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Just How Good Are The New Wave Of Ai Image Generation Tools  on twitter" href="https://twitter.com/intent/tweet/?text=Just%20How%20Good%20Are%20The%20New%20Wave%20Of%20Ai%20Image%20Generation%20Tools%20&url=https%3a%2f%2fgamestrex.github.io%2fposts%2fjust-how-good-are-the-new-wave-of-ai-image-generation-tools-%2f&hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Just How Good Are The New Wave Of Ai Image Generation Tools  on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fgamestrex.github.io%2fposts%2fjust-how-good-are-the-new-wave-of-ai-image-generation-tools-%2f&title=Just%20How%20Good%20Are%20The%20New%20Wave%20Of%20Ai%20Image%20Generation%20Tools%20&summary=Just%20How%20Good%20Are%20The%20New%20Wave%20Of%20Ai%20Image%20Generation%20Tools%20&source=https%3a%2f%2fgamestrex.github.io%2fposts%2fjust-how-good-are-the-new-wave-of-ai-image-generation-tools-%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Just How Good Are The New Wave Of Ai Image Generation Tools  on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgamestrex.github.io%2fposts%2fjust-how-good-are-the-new-wave-of-ai-image-generation-tools-%2f&title=Just%20How%20Good%20Are%20The%20New%20Wave%20Of%20Ai%20Image%20Generation%20Tools%20"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Just How Good Are The New Wave Of Ai Image Generation Tools  on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgamestrex.github.io%2fposts%2fjust-how-good-are-the-new-wave-of-ai-image-generation-tools-%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Just How Good Are The New Wave Of Ai Image Generation Tools  on whatsapp" href="https://api.whatsapp.com/send?text=Just%20How%20Good%20Are%20The%20New%20Wave%20Of%20Ai%20Image%20Generation%20Tools%20%20-%20https%3a%2f%2fgamestrex.github.io%2fposts%2fjust-how-good-are-the-new-wave-of-ai-image-generation-tools-%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Just How Good Are The New Wave Of Ai Image Generation Tools  on telegram" href="https://telegram.me/share/url?text=Just%20How%20Good%20Are%20The%20New%20Wave%20Of%20Ai%20Image%20Generation%20Tools%20&url=https%3a%2f%2fgamestrex.github.io%2fposts%2fjust-how-good-are-the-new-wave-of-ai-image-generation-tools-%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://gamestrex.github.io/>gamestrex</a></span></footer><script type=text/javascript>var _Hasync=_Hasync||[];_Hasync.push(["Histats.start","1,4595849,4,0,0,0,00010000"]),_Hasync.push(["Histats.fasi","1"]),_Hasync.push(["Histats.track_hits",""]),function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//s10.histats.com/js15_as.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}()</script><noscript><a href=/ target=_blank><img src=//sstatic1.histats.com/0.gif?4595849&101 alt border=0></a></noscript><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>